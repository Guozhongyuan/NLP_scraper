{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4014/4014 [00:00<00:00, 5738.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. convert from many txt files to one csv file\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "txts_path = \"./save_stocks\"\n",
    "\n",
    "txt_paths = []\n",
    "for root, dirs, files in os.walk(txts_path):\n",
    "    for file in files:\n",
    "        txt_paths.append(root + \"/\" + file)\n",
    "\n",
    "# 2022 data\n",
    "all = []\n",
    "for path in tqdm(txt_paths):\n",
    "    with open(path, \"r\", encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "        one = {}\n",
    "        one['time'] = data[14].replace('\\n', '')\n",
    "        one['ticker_id'] = data[1].replace('\\n', '')\n",
    "        one['ticker_name'] = data[2].replace('\\n', '')\n",
    "        one['ticker_class'] = data[13].replace('\\n', '')\n",
    "        one['ticker_grade'] = [data[5].replace('\\n', ''), data[6].replace('\\n', '')]\n",
    "        one['text_title'] = data[4].replace('\\n', '')\n",
    "        one['text_content'] = \"\".join(data[15:]).replace('\\n', '').replace(' ', '').replace('\\u3000\\u3000', '')\n",
    "        all.append(one)\n",
    "\n",
    "with open(\"./files/eastmoney_stocks.pkl\",\"wb\") as f:\n",
    "    pickle.dump(all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4014/4014 [49:40<00:00,  1.35it/s]  \n"
     ]
    }
   ],
   "source": [
    "# 2. use baidu_api to analyze\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utility.baidu_utils import BaiduNLU\n",
    "import pickle\n",
    "\n",
    "with open(\"./files/eastmoney_stocks.pkl\",\"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "config = {}\n",
    "config['APP_ID'] = '25576077'\n",
    "config['API_KEY'] = 'iprdevAUKAE15tQkgEYpCyYQ'\n",
    "config['SECRET_KEY'] = '64Zpk8fcpntYRsSyYfGmAoCMFvenGHi4'\n",
    "nlu_tool = BaiduNLU(config)\n",
    "\n",
    "all = []\n",
    "for one in tqdm(data):\n",
    "\n",
    "    title = one['text_title']\n",
    "    content = one['text_content']\n",
    "\n",
    "    # try:\n",
    "    #     res_sentiment = nlu_tool.get_sentiment(content)\n",
    "    # except Exception:\n",
    "    #     res_sentiment = {}\n",
    "\n",
    "    try:\n",
    "        res_keyword = nlu_tool.get_keyword(title, content)\n",
    "    except Exception:\n",
    "        res_keyword = {}\n",
    "\n",
    "    try:\n",
    "        res_topic = nlu_tool.get_topic(title, content)\n",
    "    except Exception:\n",
    "        res_topic = {}\n",
    "\n",
    "    # try:\n",
    "    #     res_summary = nlu_tool.get_summary(title, content, maxSummaryLen=100)\n",
    "    # except Exception:\n",
    "    #     res_summary = {}\n",
    "\n",
    "    one['text_keyword'] = res_keyword[\"items\"] if \"items\" in res_keyword.keys() else None\n",
    "    one['text_topic'] = res_topic[\"item\"] if \"item\" in res_topic.keys() else None\n",
    "\n",
    "    all.append(one)\n",
    "\n",
    "\n",
    "with open(\"./files/eastmoney_stocks_nlu.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"./files/eastmoney_stocks_nlu.pkl\", \"rb\") as f:\n",
    "    all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.941297, 'tag': '轴承'}, {'score': 0.861851, 'tag': '法兰轴承'}, {'score': 0.83386, 'tag': '股票'}, {'score': 0.799668, 'tag': '投资'}, {'score': 0.785835, 'tag': '供应商'}]\n",
      "{'lv2_tag_list': [{'score': 0.784987, 'tag': '新能源'}, {'score': 0.781917, 'tag': '投资'}], 'lv1_tag_list': [{'score': 0.456114, 'tag': '财经'}]}\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "print(all[idx]['text_keyword'])\n",
    "print(all[idx]['text_topic'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd495f9cf51c55ca6e0a09c1b63ca3d581a6ff772fd59300e24bb21842a30a9f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('lora')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
